{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bf451e",
   "metadata": {},
   "source": [
    "model I/O\n",
    "\n",
    "memory\n",
    "\n",
    "retrieval\n",
    "\n",
    "agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7279341d",
   "metadata": {},
   "source": [
    "Quantization reduces the number of bits required to represent the\n",
    "parameters of an LLM while attempting to maintain most of the original\n",
    "information.\n",
    "\n",
    "this reduces the precision slightly but easily makes up by much aster speed and low load on the vram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "929800ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Ollama with Llama3\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Initialize Ollama with Llama3\n",
    "llm = OllamaLLM(\n",
    "    model=\"llama3:latest\",  # Make sure this matches your downloaded model name\n",
    "    n_gpu_layers=-1,\n",
    "    # temperature=0.7,\n",
    "    max_tokens=500,  # Max tokens to generate\n",
    "    seed=42,\n",
    "    num_ctx=2048,\n",
    "\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c68dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is... 2!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is 1+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4cf779bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template=\"\"\"<s>[INST] <<SYS>>\n",
    "you are a helpful assistant answering concisely\n",
    "[/SYS]\n",
    "\n",
    "{user_input} [/INST]\"\"\"\n",
    "\n",
    "prompt= PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"user_input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d4320d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_chain= prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e82f089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama_user(some_text: str):\n",
    "    response=basic_chain.invoke({\"user_input\": some_text})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2db9be15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Abhimanyu!\\n\\nThe answer is: 2'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_user(\"hi! I'm Abhimanyu, what is 1+1=?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e8917dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "ntemplate=\"\"\"<s>[INST]<<SYS>>\n",
    "Create a title for a story about {summary}. Only return the title.[/SYS]\n",
    "[/INST]\"\"\"\n",
    "title_prompt=PromptTemplate(template=ntemplate, input_variable= [\"summary\"])\n",
    "\n",
    "title=LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b2ae1f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'the guy sang his heart out for her',\n",
       " 'title': '\"A Melody of Devotion\"'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title.invoke({ \"summary\":\"the guy sang his heart out for her\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bb9129af",
   "metadata": {},
   "outputs": [],
   "source": [
    "template= \"\"\"<s>[INST]<<SYS>>\n",
    "Describe the main character of a story about {summary} with the\n",
    "title {title}. Use only two sentences.[/SYS][/INST]\"\"\"\n",
    "\n",
    "character_prompt= PromptTemplate(template=template, input_variable=[\"summary\",\"title\"])\n",
    "character= LLMChain(llm=llm, prompt= character_prompt, output_key=\"character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1a1dcaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST]<<SYS>>\n",
    "Create a story about {summary} with the title {title}. The main\n",
    "character is: {character}. Only return the story and it cannot be\n",
    "longer than one paragraph.[/SYS][/INST]\"\"\"\n",
    "story_prompt= PromptTemplate(template=template, input_variable= [\"summary\",\"title\",\"character\"])\n",
    "\n",
    "story= LLMChain(llm=llm, prompt=story_prompt, output_key=\"story\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f11e90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain= title | character | story\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c003915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'the guy sang his heart out for her',\n",
       " 'title': '\"A Melody of Devotion\"',\n",
       " 'character': 'The main character, Ethan, is a shy and introverted music teacher who pours his heart and soul into writing and performing a love song dedicated to the woman he loves, Sophia. With every note and lyric, Ethan hopes to convey the depth of his emotions and win her heart, even if it means risking rejection and hurt.',\n",
       " 'story': '<EVENT>[A Melody of Devotion]</EVENT>\\n\\nEthan stood nervously on stage, his guitar trembling in his hands as he gazed out at Sophia. The dim lights of the small coffee shop seemed to fade into the background as he began to sing his heart out, pouring every ounce of emotion into the lyrics of \"A Melody of Devotion\". His voice wavered slightly at first, but as he hit the chorus, a fierce passion took over, his words tumbling out in a rush of sincerity. \"Oh Sophia, my love for you is like a symphony, playing sweet melodies on my heartstrings,\" he sang, his eyes locked onto hers with an unspoken plea. The air was electric with tension as Sophia\\'s face transformed from surprise to wonder, her eyes welling up with tears as Ethan\\'s melody wrapped itself around her very being.'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(\"the guy sang his heart out for her\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e493d",
   "metadata": {},
   "source": [
    "so now we have a chain and we only need to give it summary and get distintly all the elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df43bb80",
   "metadata": {},
   "source": [
    "**memory** --these models are stateless rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ca19bd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Abhimanyu!\\n\\nThe answer is: 2'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_user(\"hi! I'm Abhimanyu, what is 1+1=?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ceee6cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not aware of your name. You haven't provided it to me yet! Would you like to share?\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_user(\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eb3f4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST]<<SYS>>your are a general assistant, be concise and to the point in your answers\n",
    "[/SYS]{chat_history}{user_input}[/INST]\"\"\"\n",
    "\n",
    "prompt= PromptTemplate(template=template, input_variable=[\"user_input\",\"chat_history\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b2cfd0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory=ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "mllm= LLMChain(llm=llm,prompt=prompt,memory=memory,output_key=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "36bfc99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': \"hi! I'm Abhimanyu, what is 1+1=?\",\n",
       " 'chat_history': '',\n",
       " 'answer': 'Nice to meet you, Abhimanyu!\\n\\nThe answer is: 2'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mllm.invoke({\"user_input\":\"hi! I'm Abhimanyu, what is 1+1=?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "425fac83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'say my name?',\n",
       " 'chat_history': \"Human: hi! I'm Abhimanyu, what is 1+1=?\\nAI: Nice to meet you, Abhimanyu!\\n\\nThe answer is: 2\\nHuman: what is my name?\\nAI: Nice to meet you too, Abhimanyu!\\n\\nYour name is: Abhimanyu\",\n",
       " 'answer': '<INST>\\n<SYS>>AI: Your name is indeed \"Abhimanyu\".'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mllm.invoke({\"user_input\":\"say my name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8fb9db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to only save upto k conversations in history so that we do not run out of token limit\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory=ConversationBufferWindowMemory(k=2, memory_key=\"chat_history\")\n",
    "mllm= LLMChain(llm=llm,prompt=prompt,memory=memory,output_key=\"answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48925b0",
   "metadata": {},
   "source": [
    "now the size reduces but the longer histories are traded off..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d462a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation memory\n",
    "summary_prompt_template=\"\"\"you are a summarizer\n",
    "summarise the conversations and update with the new lines.\n",
    "Current summary:\n",
    "{summary}\n",
    "new lines of conversation:\n",
    "{new_lines}\n",
    "New summary: \"\"\"\n",
    "\n",
    "summary_prompt= PromptTemplate(template=summary_prompt_template, input_variables=[\"new_lines\",\"summary\"])\n",
    "\n",
    "\n",
    "\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "memory=ConversationSummaryMemory(llm=llm, memory_key=\"chat_history\", prompt=summary_prompt)\n",
    "llm_chain=LLMChain(llm=llm, prompt=prompt, memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "248c3311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': \"hi! i'm abhimanyu\",\n",
       " 'chat_history': '',\n",
       " 'text': \"Hello Abhimanyu! I'm here to assist you with any queries or tasks. What can I help you with today?\"}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(\"hi! i'm abhimanyu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "79c178db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'what is 1+1',\n",
       " 'chat_history': \"Here is the updated summary:\\n\\n**Summary:** A conversation has just started between Human (Abhimanyu) and AI. The human introduces himself as Abhimanyu, and the AI responds by introducing itself and offering assistance.\\n\\nLet me know when you're ready to add more lines to the conversation!\",\n",
       " 'text': '<s>[INST]<<SYS>>The answer to 1+1 is 2.[/SYS]'}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(\"what is 1+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "acc721f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'what is your name in one word',\n",
       " 'chat_history': 'I\\'m ready!\\n\\nHere\\'s the updated summary:\\n\\n**Summary:** A conversation has started between Human (Abhimanyu) and AI. The human introduces himself as Abhimanyu, and the AI responds by introducing itself and offering assistance. The human then asks a simple math question \"what is 1+1\", and the AI answers correctly that the answer is 2.\\n\\nLet me know when you\\'re ready to add more lines to the conversation!',\n",
       " 'text': '<INST>\\n\\n**Answer:** Zeta'}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(\"what is your name in one word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3a6af6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'what is 8+11?',\n",
       " 'chat_history': 'Here\\'s the updated summary:\\n\\n**Summary:** A conversation has started between Human (Abhimanyu) and AI. The human introduces himself as Abhimanyu, and the AI responds by introducing itself as Zeta and offering assistance. The human then asks a few questions to get to know the AI better: first, he asks \"what is 1+1\", and the AI answers correctly that the answer is 2. Next, he asks for the AI\\'s name in one word, to which the AI responds with the single word \"<INST>\", which is later revealed to be Zeta.\\n\\nLet me know when you\\'re ready to add more lines to the conversation!',\n",
       " 'text': '19'}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(\"what is 8+11?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682e47d4",
   "metadata": {},
   "source": [
    "hallucinated :-:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b6552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': 'I\\'m ready!\\n\\nHere\\'s the updated summary:\\n\\n**Summary:** A conversation has started between Human (Abhimanyu) and AI (Zeta). The human introduces himself as Abhimanyu, and Zeta responds by introducing itself as Zeta and offering assistance. The human then asks a few questions to get to know the AI better: first, he asks \"what is 1+1\", and Zeta answers correctly that the answer is 2. Next, he asks for Zeta\\'s name in one word, to which Zeta responds with the single word \"<INST>\", which is later revealed to be its own name. The human then asks another math question: \"what is 8+11?\", and Zeta answers correctly that the result is 19.\\n\\nLet me know when you\\'re ready to add more lines to the conversation!'}\n"
     ]
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4609f36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'what was my first question?',\n",
       " 'chat_history': 'I\\'m ready!\\n\\nHere\\'s the updated summary:\\n\\n**Summary:** A conversation has started between Human (Abhimanyu) and AI (Zeta). The human introduces himself as Abhimanyu, and Zeta responds by introducing itself as Zeta and offering assistance. The human then asks a few questions to get to know the AI better: first, he asks \"what is 1+1\", and Zeta answers correctly that the answer is 2. Next, he asks for Zeta\\'s name in one word, to which Zeta responds with the single word \"<INST>\", which is later revealed to be its own name. The human then asks another math question: \"what is 8+11?\", and Zeta answers correctly that the result is 19.\\n\\nLet me know when you\\'re ready to add more lines to the conversation!',\n",
       " 'text': 'Your first question was \"what is 1+1\"?'}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(\"what was my first question?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4937b17b",
   "metadata": {},
   "source": [
    "**AGENTS,** \n",
    "framework: reasoning and acting ( ReAct) \n",
    "\n",
    "\n",
    "3 steps: \n",
    "\n",
    "\n",
    "Thought\n",
    "Action\n",
    "Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdef5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
